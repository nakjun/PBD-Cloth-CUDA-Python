import torch
import numpy as np
from numba import cuda
import sys
import os
import math
import argparse
import csv  # [NEW] CSV ì €ì¥ì„ ìœ„í•œ ëª¨ë“ˆ

# [User Imports] ìë„¤ê°€ ì •ì˜í•œ ê²½ë¡œ ì„¤ì •
sys.path.append('../')

# === ì¶”ê°€: save_obj_with_heatmap ì„í¬íŠ¸ ===
try:
    from main import save_obj_with_heatmap
except ImportError:
    # ë§Œì•½ main.pyì—ì„œ ì„í¬íŠ¸ê°€ ì•ˆ ë  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë‚´ë¶€ì— ì •ì˜ (í˜¹ì€ None ì²˜ë¦¬)
    # ì—¬ê¸°ì„œëŠ” ì•„ë˜ì— ì •ì˜ëœ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ pass
    pass

# 1. ì»¤ë„ Import
from cloth_cuda_optimized import compute_features_kernel, solve_self_collision_masked_kernel, solve_ground_collision_kernel
from PBD.module import predict_position_kernel, update_velocity_kernel, compute_hash_kernel, find_cell_start_end_kernel
from PBD.coloring import compute_graph_coloring
from PBD.module import solve_distance_constraint_colored_kernel 

# ------------------------------------------------------------------------------
# Helper Function: OBJ Save with Heatmap
# ------------------------------------------------------------------------------
def save_obj_with_heatmap(filename, vertices, penetrations, width, height, thickness):
    """
    [Heatmap Visualization]
    thickness: ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ì‚¬ìš©ëœ íŒŒí‹°í´ì˜ ë°˜ì§€ë¦„ (self.thickness)
    """
    diameter = thickness * 2.0
    ignore_threshold = diameter * 0.05 
    critical_threshold = diameter * 0.3 

    with open(filename, 'w') as f:
        f.write("# Cloth Simulation Step with Calibrated Heatmap\n")
        for i, v in enumerate(vertices):
            depth = penetrations[i]
            
            ratio = 0.0
            if depth <= ignore_threshold:
                ratio = 0.0
            else:
                ratio = (depth - ignore_threshold) / (critical_threshold - ignore_threshold)
                ratio = min(max(ratio, 0.0), 1.0)
            
            r = 1.0
            g = 1.0 - ratio
            b = 1.0 - ratio
            f.write(f"v {v[0]:.4f} {v[1]:.4f} {v[2]:.4f} {r:.4f} {g:.4f} {b:.4f}\n")

        for y in range(height - 1):
            for x in range(width - 1):
                idx = y * width + x + 1
                f.write(f"f {idx} {idx + width} {idx + 1}\n")
                f.write(f"f {idx + 1} {idx + width} {idx + width + 1}\n")

# ------------------------------------------------------------------------------
# Class Definition
# ------------------------------------------------------------------------------
class PowerfulClothSim:
    def __init__(self, width, height, model_path, spacing=0.1):
        """
        ì´ˆê°•ë ¥ AI ê¸°ë°˜ ì²œ ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„ ì´ˆê¸°í™”
        """
        self.width = width
        self.height = height
        self.num_particles = width * height
        self.spacing = spacing
        
        # ë¬¼ë¦¬ íŒŒë¼ë¯¸í„°
        self.dt = 0.001
        self.substeps = 10 
        self.gravity = -9.8

        lift_height = 3.0 # 3ë¯¸í„° ìƒê³µì—ì„œ ì‹œì‘
        
        print(f"âš¡ Initializing PowerfulClothSim ({width}x{height})")
        print(f"   - Particles: {self.num_particles}")

        # 1. Host Data Setup
        pos_host = np.zeros((self.num_particles, 3), dtype=np.float32)
        # [í•µì‹¬ ì„¤ì •]
        start_y = 1.5 # ë°”ë‹¥ì—ì„œ 1ë¯¸í„° ì •ë„ ë„ì›€ (ë„ˆë¬´ ë†’ìœ¼ë©´ ë–¨ì–´ì§€ë‹¤ í´ì§)
        
        # ì£¼ë¦„ íŒŒë¼ë¯¸í„° (Stackingì„ ìœ ë„í•˜ëŠ” ê°€ì´ë“œ)
        fold_frequency = 10.0 # ì£¼ë¦„ì˜ ë¹ˆë„ (ë†’ì„ìˆ˜ë¡ ìì˜í•˜ê²Œ ì ‘í˜)
        fold_amplitude = spacing * 0.5 # ì£¼ë¦„ì˜ ê¹Šì´ (ë„ˆë¬´ ê¹Šìœ¼ë©´ ì´ë¯¸ ì ‘íŒ ìƒíƒœ)

        for y in range(height):
            for x in range(width):
                idx = y * width + x
                
                # Xì¶•: ì •ê°„ê²© ë°°ì¹˜
                pos_x = x * spacing
                
                # Yì¶•: ìˆ˜ì§ìœ¼ë¡œ ë°°ì¹˜í•˜ë˜, ê³µì¤‘ì— ë„ì›€
                # (heightê°€ í´ìˆ˜ë¡ ìœ„ë¡œ ê¸¸ê²Œ ë»—ìŒ)
                pos_y = (height * spacing) - (y * spacing) + start_y
                
                # [í•µì‹¬] Zì¶•: Y ë†’ì´ì— ë”°ë¼ Sine Waveë¥¼ ì¤Œ
                # ì´ê²ƒì´ "ì ‘íˆëŠ” ë°©í–¥"ì„ ê²°ì •í•¨ (ì§€ê·¸-ì¬ê·¸ ìœ ë„)
                # yê°€ ë³€í•¨ì— ë”°ë¼ zê°€ ì•ë’¤ë¡œ í”ë“¤ë¦¼
                pos_z = math.sin(y * 0.5) * fold_amplitude
                
                # (ì˜µì…˜) ì•½ê°„ ê¸°ìš¸ì—¬ì„œ ë–¨ì–´ëœ¨ë¦¬ë©´ ë” ìì—°ìŠ¤ëŸ¬ì›€ (Random Tilt)
                # pos_z += y * 0.01 
                
                pos_host[idx] = [pos_x, pos_y, pos_z]
        

        # for y in range(height):
        #     for x in range(width):
        #         idx = y * width + x
                
        #         # [ë³€ê²½ 1] Xì¶•: ì••ì¶• ì—†ì´ ì •ê°„ê²© ë°°ì¹˜
        #         pos_x = x * spacing 
                
        #         # [ë³€ê²½ 2] Yì¶•: ê³µì¤‘ì— ë„ì›€ (ì»¤íŠ¼ì²˜ëŸ¼ ìˆ˜ì§ìœ¼ë¡œ ë°°ì¹˜)
        #         # ë°”ë‹¥(0.0)ì— ë‹¿ì„ ë•Œê¹Œì§€ ë–¨ì–´ì§€ë„ë¡ ë†’ì´ ì„¤ì •
        #         pos_z = (-y * spacing) + (height * spacing) + lift_height
                
        #         # [ë³€ê²½ 3] Zì¶•: Sine Wave ëŒ€ì‹  'ë¯¸ì„¸í•œ ë…¸ì´ì¦ˆ' ì¶”ê°€
        #         # ì™„ë²½í•œ í‰ë©´ì€ ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ì˜¤íˆë ¤ ë¶€ìì—°ìŠ¤ëŸ¬ì›€ (Buckling ìœ ë„ìš©)
        #         # -0.01 ~ 0.01 ì •ë„ì˜ ì•„ì£¼ ì‘ì€ ë‚œìˆ˜
        #         pos_y = np.random.uniform(2.5, 3.5) 
                
        #         pos_host[idx] = [pos_x, pos_y, pos_z]
        
        # ì•„ì½”ë””ì–¸ ì£¼ë¦„ ì´ˆê¸°í™”
        compression_ratio = 0.3
        # for y in range(height):
        #     for x in range(width):
        #         idx = y * width + x
        #         freq = 1.5
        #         amp = spacing * 2.0
        #         z_offset = np.sin(x * freq) * amp
        #         pos_host[idx] = [
        #             x * spacing * compression_ratio, 
        #             -y * spacing + (height * spacing), 
        #             z_offset
        #         ]

        # for y in range(height):
        #     for x in range(width):
        #         idx = y * width + x
                
        #         freq = 1.5 
        #         amp = spacing * 2.0 
        #         z_offset = np.sin(x * freq) * amp # ì‚¬ì¸íŒŒ ì£¼ë¦„
                
        #         pos_host[idx] = [
        #             x * spacing * compression_ratio, 
        #             # [í•µì‹¬] Yì¶• ì¢Œí‘œë¥¼ lift_height ë§Œí¼ ë“¤ì–´ì˜¬ë¦¼
        #             -y * spacing + (height * spacing) + lift_height, 
        #             z_offset
        #         ]

        # [ìˆ˜ì •] ì œì•½ ì¡°ê±´ ìƒì„± (Structural + Shear)
        constraints = []
        for y in range(height):
            for x in range(width):
                idx = y * width + x
                
                # 1. Structural (ê°€ë¡œ/ì„¸ë¡œ) - ê¸°ì¡´
                if x < width - 1: 
                    constraints.append([idx, idx + 1])
                if y < height - 1: 
                    constraints.append([idx, idx + width])
                
                # 2. Shear (ëŒ€ê°ì„ ) - [NEW] ì¶”ê°€!
                # ì²œì˜ ë’¤í‹€ë¦¼ì„ ë§‰ì•„ì£¼ì–´ í˜•íƒœë¥¼ ìœ ì§€í•¨
                if x < width - 1 and y < height - 1:
                    constraints.append([idx, idx + width + 1])      # â†˜ ëŒ€ê°ì„ 
                    constraints.append([idx + 1, idx + width])      # â†™ ëŒ€ê°ì„ 
        
        
        # # ì œì•½ ì¡°ê±´ ìƒì„±
        # constraints = []
        # for y in range(height):
        #     for x in range(width):
        #         idx = y * width + x
        #         if x < width - 1: constraints.append([idx, idx + 1])
        #         if y < height - 1: constraints.append([idx, idx + width])
        
        self.num_constraints = len(constraints)
        
        # 2. Graph Coloring
        print("ğŸ¨ Computing Graph Coloring...")
        color_batches_host = compute_graph_coloring(self.num_particles, constraints)
        self.d_color_batches = [cuda.to_device(batch) for batch in color_batches_host]
        
        # Rest Lengths
        constraints = np.array(constraints, dtype=np.int32)
        # rest_lengths = np.full(self.num_constraints, spacing, dtype=np.float32)
        rest_lengths_list = []
        for y in range(height):
            for x in range(width):
                # Structural
                if x < width - 1: rest_lengths_list.append(spacing)
                if y < height - 1: rest_lengths_list.append(spacing)
                # Shear
                if x < width - 1 and y < height - 1:
                    rest_lengths_list.append(spacing * math.sqrt(2)) # ëŒ€ê°ì„  ê¸¸ì´
                    rest_lengths_list.append(spacing * math.sqrt(2))

        rest_lengths = np.array(rest_lengths_list, dtype=np.float32)

        # 3. GPU Memory Allocation
        self.d_pos = cuda.to_device(pos_host)
        self.d_pos_pred = cuda.device_array_like(self.d_pos)
        self.d_vel = cuda.to_device(np.zeros_like(pos_host))
        self.d_constraints = cuda.to_device(constraints)
        self.d_rest_lengths = cuda.to_device(rest_lengths)
        
        mass_inv = np.ones(self.num_particles, dtype=np.float32)
        mass_inv[0] = 0.0 
        # mass_inv[width-1] = 0.0 
        self.d_mass_inv = cuda.to_device(mass_inv)
        
        # Spatial Hashing Buffers
        # [Optimized] 100ë§Œ íŒŒí‹°í´(1024^2) ëŒ€ì‘ì„ ìœ„í•´ í•´ì‹œ í¬ê¸° ì¦ì„¤ (ì•½ 300ë§Œ)
        self.HASH_SIZE = 2999999 
        self.d_particle_hashes = cuda.device_array(self.num_particles, dtype=np.int32)
        self.d_particle_indices = cuda.device_array(self.num_particles, dtype=np.int32)
        self.d_cell_start = cuda.device_array(self.HASH_SIZE, dtype=np.int32)
        self.d_cell_end = cuda.device_array(self.HASH_SIZE, dtype=np.int32)
        self.thickness = spacing * 0.3
        self.d_penetration = cuda.device_array(self.num_particles, dtype=np.float32)

        # CUDA Config
        self.threads = 256
        self.blocks = (self.num_particles + 255) // 256
        
        # 4. AI & Zero-Copy Setup
        print(f"ğŸ§  Loading AI Brain from {model_path}...")
        
        if os.path.exists(model_path):
            self.ai_model = torch.nn.Sequential(
                torch.nn.Linear(4, 32),
                torch.nn.ReLU(),
                torch.nn.Linear(32, 16),
                torch.nn.ReLU(),
                torch.nn.Linear(16, 1),
                torch.nn.Sigmoid()
            ).cuda()
            
            checkpoint = torch.load(model_path, map_location='cuda')
            new_state_dict = {k.replace("net.", ""): v for k, v in checkpoint.items()}
            self.ai_model.load_state_dict(new_state_dict, strict=False)
            self.ai_model.eval()
            
            try:
                self.ai_model = torch.compile(self.ai_model)
                print("ğŸš€ PyTorch 2.0 Compiled Model Activated!")
            except:
                pass
        else:
            raise FileNotFoundError("Model not found!")

        self.d_features = cuda.device_array((self.num_particles, 4), dtype=np.float32)
        self.d_risk_mask = cuda.device_array(self.num_particles, dtype=np.float32)
        
        self.frame_count = 0
        self.ai_interval = 10 
        
        print("âœ… Simulation Engine Ready. Let's Rock.")

    def _numba_to_torch(self, numba_array):
        return torch.as_tensor(numba_array, device='cuda')

    def _run_ai_culling(self):
        """
        AI ê¸°ë°˜ ì¶©ëŒ ê°€ì§€ì¹˜ê¸° (Frame ë‹¹ 1íšŒ ìˆ˜í–‰ ê¶Œì¥)
        """
        # 1. Feature Extraction (GPU Kernel)
        # CPU ê°œì… ì—†ì´ GPU ì•ˆì—ì„œë§Œ ë°ì´í„° ì´ë™
        compute_features_kernel[self.blocks, self.threads](
            self.d_pos, self.d_vel, self.d_features,
            self.width, self.height, self.spacing
        )
        # 2. Inference (Zero-Copy)
        input_tensor = self._numba_to_torch(self.d_features)
        with torch.no_grad():
            # (N, 4) -> Model -> (N, 1)
            probs = self.ai_model(input_tensor)
            # Thresholding (0.5)
            # (N, 1) -> (N, )
            mask_tensor = (probs > 0.5).float().squeeze()
            # 3. Write back to Numba Buffer [FIXED]
            # PyTorch Tensor -> Numba Wrapper ë³€í™˜
            # (mask_tensorê°€ ë©”ëª¨ë¦¬ìƒ ì—°ì†ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ contiguous() í˜¸ì¶œ í•„ìˆ˜)
            cuda_mask_view = cuda.as_cuda_array(mask_tensor.contiguous())
            # [í•µì‹¬ ìˆ˜ì •] ìŠ¬ë¼ì´ì‹± ëŒ€ì…ì„ ì´ìš©í•œ Device-to-Device Copy
            self.d_risk_mask[:] = cuda_mask_view
            # self.d_risk_mask[:] = 1.0


    
    # def _run_ai_culling(self):
    #     compute_features_kernel[self.blocks, self.threads](
    #         self.d_pos, self.d_vel, self.d_features,
    #         self.width, self.height, self.spacing
    #     )
        
    #     input_tensor = self._numba_to_torch(self.d_features)
        
    #     with torch.no_grad():
    #         probs = self.ai_model(input_tensor)
    #         mask_tensor = (probs > 0.5).float().squeeze() 
    #         cuda_mask_view = cuda.as_cuda_array(mask_tensor.contiguous())
    #         self.d_risk_mask[:] = cuda_mask_view

    def _sort_particles_torch(self):
        hashes_torch = self._numba_to_torch(self.d_particle_hashes)
        indices_torch = self._numba_to_torch(self.d_particle_indices)
        
        sorted_indices = torch.argsort(hashes_torch)
        
        hashes_sorted = hashes_torch[sorted_indices]
        indices_sorted = indices_torch[sorted_indices]
        
        self.d_particle_hashes[:] = cuda.as_cuda_array(hashes_sorted.contiguous())
        self.d_particle_indices[:] = cuda.as_cuda_array(indices_sorted.contiguous())

    def step(self):
        dt_sub = self.dt / self.substeps
        
        # [Step 1] AI Culling (Interleaved)
        if self.frame_count % self.ai_interval == 0:
            self._run_ai_culling()
        
        self.frame_count += 1
        
        # [Step 2] PBD Substeps
        for _ in range(self.substeps):
            predict_position_kernel[self.blocks, self.threads](
                self.d_pos, self.d_vel, self.d_pos_pred, self.d_mass_inv, 
                dt_sub, self.gravity, self.num_particles
            )
            
            for d_batch in self.d_color_batches:
                blocks_c = (d_batch.shape[0] + 255) // 256
                solve_distance_constraint_colored_kernel[blocks_c, 256](
                    self.d_pos_pred, self.d_mass_inv, self.d_constraints, 
                    self.d_rest_lengths, d_batch, dt_sub, 0.8
                )
            
            self.d_cell_start[:] = -1
            self.d_cell_end[:] = -1
            compute_hash_kernel[self.blocks, self.threads](
                self.d_pos_pred, self.d_particle_hashes, self.d_particle_indices, self.num_particles
            )
            
            self._sort_particles_torch()
            
            find_cell_start_end_kernel[self.blocks, self.threads](
                self.d_particle_hashes, self.d_cell_start, self.d_cell_end, self.num_particles
            )

            solve_ground_collision_kernel[self.blocks, self.threads](
                self.d_pos_pred, self.d_pos, self.d_vel, 
                self.num_particles, 0.0, 0.5
            )

            
            solve_self_collision_masked_kernel[self.blocks, self.threads](
                self.d_pos_pred, self.d_mass_inv,
                self.d_cell_start, self.d_cell_end,
                self.d_particle_indices, self.d_particle_hashes,
                self.d_risk_mask,
                self.num_particles, self.thickness, self.d_penetration
            )
            
            update_velocity_kernel[self.blocks, self.threads](
                self.d_pos, self.d_vel, self.d_pos_pred, dt_sub, self.num_particles
            )

    # --- Data Access ---
    def get_positions(self):
        return self.d_pos.copy_to_host()
    
    def get_risk_mask(self):
        return self.d_risk_mask.copy_to_host()

    def get_penetrations(self):
        return self.d_penetration.copy_to_host()

# ------------------------------------------------------------------------------
# Main Logic with Arguments
# ------------------------------------------------------------------------------
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Powerful AI Cloth Simulation Engine")
    parser.add_argument("--type", type=int, default=1, 
                        help="Mode 1: Single FPS Benchmark, Mode 2: Extract OBJ, Mode 3: Grid Search Benchmark")
    args = parser.parse_args()

    # ëª¨ë¸ ê²½ë¡œ
    MODEL_PATH = "../MLP/best_model_v2.pth"

    # [Type 3ê°€ ì•„ë‹ ë•Œë§Œ ê¸°ë³¸ 1024x1024 ìƒì„±]
    # Grid Search ë•ŒëŠ” í•´ìƒë„ë¥¼ ë°”ê¿”ê°€ë©° ìƒì„±í•´ì•¼ í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ìƒì„±í•˜ì§€ ì•Šê±°ë‚˜, ìƒì„± í›„ ë¬´ì‹œí•¨.
    if args.type != 3:
        # 1. ì´ˆê¸°í™” (ê¸°ë³¸)
        sim = PowerfulClothSim(128, 128, MODEL_PATH, spacing=0.1)
        print("ğŸ”¥ Warming up GPU...")
        for _ in range(10): sim.step()
        torch.cuda.synchronize()

    # ==========================================
    # TYPE 1: Average FPS Benchmark (Single)
    # ==========================================
    if args.type == 1:
        print("\n[MODE 1] Starting FPS Benchmark (1024x1024)...")
        
        start_event = torch.cuda.Event(enable_timing=True)
        end_event = torch.cuda.Event(enable_timing=True)
        
        total_time_sum = 0.0
        avg_active_ratio = 0.0
        
        print("â±ï¸  Profiling 100 frames...")
        
        for i in range(100):
            start_event.record()
            sim.step()
            end_event.record()
            torch.cuda.synchronize()
            
            frame_time = start_event.elapsed_time(end_event)
            total_time_sum += frame_time
            
        avg_fps = 1000.0 / (total_time_sum / 100)
        print("="*40)
        print(f"ğŸš€ Final Result:")
        print(f"   - Average FPS: {avg_fps:.2f}")
        print(f"   - Avg Active Ratio: {(avg_active_ratio/100)*100:.1f}%")
        print("="*40)

    # ==========================================
    # TYPE 2: Extract OBJ Files
    # ==========================================
    elif args.type == 2:
        print("\n[MODE 2] Extracting OBJ files with Heatmap...")
        
        output_dir = "extracted_objs_baseline_v3"
        os.makedirs(output_dir, exist_ok=True)
        
        TOTAL_FRAMES = 3000
        SAVE_INTERVAL = 10
        
        print(f"ğŸ“‚ Output Directory: {output_dir}")

        for i in range(TOTAL_FRAMES):
            sim.step()
            
            if i % SAVE_INTERVAL == 0:
                pos = sim.get_positions()
                pen = sim.get_penetrations()
                
                filename = os.path.join(output_dir, f"cloth_{i:04d}.obj")
                save_obj_with_heatmap(
                    filename, pos, pen, sim.width, sim.height, sim.thickness
                )
                print(f"   ğŸ’¾ Saved: {filename}", end='\r')
        
        print(f"\nâœ… Extraction Complete! Check '{output_dir}' folder.")

    # ==========================================
    # TYPE 3: Grid Search Benchmark (CSV Save)
    # ==========================================
    elif args.type == 3:
        print("\n[MODE 3] Starting Grid Search Benchmark...")
        
        # [Grid Search Settings]
        # Cloth Simulationì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” í•´ìƒë„ (2ì˜ ì œê³±ìˆ˜)
        resolutions = [64, 128, 256, 512, 1024] 
        csv_filename = "grid_search_results.csv"
        
        # CSV íŒŒì¼ ì´ˆê¸°í™”
        with open(csv_filename, mode='w', newline='') as file:
            writer = csv.writer(file)
            writer.writerow(["Resolution", "Particles", "Average_FPS", "Average_Active_Ratio_Percent"])

        print(f"ğŸ“‹ Resolutions to test: {resolutions}")
        print(f"ğŸ’¾ Results will be saved to: {csv_filename}")

        for res in resolutions:
            print("\n" + "-"*50)
            print(f"ğŸ§ª Testing Resolution: {res} x {res}")
            print("-"*50)

            # ë©”ëª¨ë¦¬ ì •ë¦¬ (ì´ì „ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° í•´ì œ)
            if 'sim' in locals():
                del sim
            torch.cuda.empty_cache()

            try:
                # 1. ì‹œë®¬ë ˆì´ì…˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                # ì—¬ê¸°ì„œëŠ” ë¹„êµ í†µì œë¥¼ ìœ„í•´ spacing ê³ ì •
                sim = PowerfulClothSim(res, res, MODEL_PATH, spacing=0.1)
                
                # Warmup
                print("   ğŸ”¥ Warming up...")
                for _ in range(10): sim.step()
                torch.cuda.synchronize()

                # 2. ë²¤ì¹˜ë§ˆí‚¹
                start_event = torch.cuda.Event(enable_timing=True)
                end_event = torch.cuda.Event(enable_timing=True)
                
                total_time_sum = 0.0
                avg_active_ratio = 0.0
                TEST_FRAMES = 100

                print(f"   â±ï¸  Profiling {TEST_FRAMES} frames...")
                
                for i in range(TEST_FRAMES):
                    start_event.record()
                    sim.step()
                    end_event.record()
                    torch.cuda.synchronize()
                    
                    frame_time = start_event.elapsed_time(end_event)
                    total_time_sum += frame_time
                    
                    # Benchmark ê³¼ì •ì—ì„œëŠ” mask copyë¥¼ í•˜ì§€ ì•ŠìŒ
                    # ì¦‰, active ratio ì¸¡ì • ì½”ë“œë„ ìƒëµ
                    # (ì•„ë˜ Block ì™„ì „íˆ ì œê±°)
                    # if i % 10 == 0:
                    #     mask = sim.d_risk_mask.copy_to_host()
                    #     active_count = np.sum(mask > 0.5)
                    #     avg_active_ratio += (active_count / sim.num_particles)

                # ê²°ê³¼ ê³„ì‚°
                avg_fps = 1000.0 / (total_time_sum / TEST_FRAMES)
                # ì‹¤ì œë¡œ active ratio ì¸¡ì •ì„ ìƒëµí–ˆìœ¼ë¯€ë¡œ 0.0ìœ¼ë¡œ ì„¤ì •
                final_active_ratio = 0.0

                print(f"   âœ… Result: {avg_fps:.2f} FPS | Active: {final_active_ratio:.2f}%")

                # CSV ì €ì¥
                with open(csv_filename, mode='a', newline='') as file:
                    writer = csv.writer(file)
                    writer.writerow([f"{res}x{res}", sim.num_particles, f"{avg_fps:.2f}", f"{final_active_ratio:.2f}"])

            except Exception as e:
                print(f"   âŒ Error at {res}x{res}: {e}")
                # ì—ëŸ¬ë‚˜ë©´ CSVì— ì—ëŸ¬ ê¸°ë¡
                with open(csv_filename, mode='a', newline='') as file:
                    writer = csv.writer(file)
                    writer.writerow([f"{res}x{res}", "ERROR", "0.0", "0.0"])

        print("\nğŸ‰ Grid Search Complete! Data saved to CSV.")