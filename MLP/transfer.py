import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, ConcatDataset
import numpy as np
import os
import glob
from tqdm import tqdm

# 1. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (ê¸°ì¡´ê³¼ ë™ì¼)
class ClothCollisionDataset(Dataset):
    def __init__(self, data_dir):
        # í•´ë‹¹ ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  npz íŒŒì¼ ê²€ìƒ‰
        self.file_list = sorted(glob.glob(os.path.join(data_dir, "*.npz")))
        print(f"ğŸ“‚ Found {len(self.file_list)} data files in '{data_dir}'.")
        
    def __len__(self):
        return len(self.file_list)
    
    def __getitem__(self, idx):
        try:
            data = np.load(self.file_list[idx])
            
            # [Input 1] ì†ë„ (N, 3)
            vel = data['vel'] 
            
            # [Input 2] ê¸°í•˜ ì •ë³´ (N, 1)
            # ë°ì´í„° ì €ì¥ ë°©ì‹ì— ë”°ë¼ shapeì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ reshape
            geo = data['geo'].reshape(-1, 1) 
            
            # [Feature Fusion] (N, 4) -> [vx, vy, vz, strain]
            features = np.hstack((vel, geo))
            
            # [Label] ì¹¨íˆ¬ ê¹Šì´ (Binary Classification)
            penetration = data['label'] 
            label = (penetration > 0.001).astype(np.float32) 
            
            return torch.FloatTensor(features), torch.FloatTensor(label)
        except Exception as e:
            print(f"âŒ Error loading {self.file_list[idx]}: {e}")
            # ì—ëŸ¬ ë°œìƒ ì‹œ 0ìœ¼ë¡œ ì±„ìš´ ë”ë¯¸ ë°ì´í„° ë°˜í™˜ (í•™ìŠµ ì¤‘ë‹¨ ë°©ì§€)
            return torch.zeros((1, 4)), torch.zeros((1,))

# 2. ëª¨ë¸ ì •ì˜ (ê¸°ì¡´ê³¼ ë™ì¼)
class CollisionPredictor(nn.Module):
    def __init__(self):
        super(CollisionPredictor, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(4, 64),
            nn.ReLU(),
            nn.Linear(64, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.BatchNorm1d(16),
            nn.ReLU(),
            nn.Linear(16, 8),
            nn.ReLU(),
            nn.Linear(8, 1),
            nn.Sigmoid() 
        )
        
    def forward(self, x):
        return self.net(x)

def transfer_train():
    # ---------------------------------------------------------
    # [ì„¤ì •] ì „ì´ í•™ìŠµ íŒŒë¼ë¯¸í„°
    # ---------------------------------------------------------
    # 1. í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ì…‹ í´ë” ë¦¬ìŠ¤íŠ¸ (ì—¬ê¸°ì— ìƒˆ ë°ì´í„° ê²½ë¡œ ì¶”ê°€)
    DATA_DIRS = [
        "../dataset_curtain_128",   # ê¸°ì¡´ ë°ì´í„° (Scene 1)
        "../dataset_flag_128",    # ìƒˆë¡œìš´ ë°ì´í„° (Scene 2)
        "../dataset_pin_128"           # ìƒˆë¡œìš´ ë°ì´í„° (Scene 3)
    ]
    
    PRETRAINED_MODEL_PATH = "best_model_v2.pth" # ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
    SAVE_MODEL_PATH = "best_model_adapted.pth"  # ì „ì´ í•™ìŠµ í›„ ì €ì¥í•  ëª¨ë¸ëª…
    
    BATCH_SIZE = 1 
    LR = 0.0001 # Fine-tuningì„ ìœ„í•´ í•™ìŠµë¥ ì„ ë‚®ì¶¤ (0.001 -> 0.0001)
    EPOCHS = 5  # ì ì‘(Adaptation)ì€ ì ì€ ì—í­ìœ¼ë¡œë„ ì¶©ë¶„í•  ìˆ˜ ìˆìŒ
    
    # ---------------------------------------------------------
    # [ë°ì´í„°ì…‹ ë³‘í•©] ì—¬ëŸ¬ í´ë”ì˜ ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨
    # ---------------------------------------------------------
    datasets = []
    for d_dir in DATA_DIRS:
        if os.path.exists(d_dir):
            datasets.append(ClothCollisionDataset(d_dir))
        else:
            print(f"âš ï¸ Warning: Directory '{d_dir}' not found. Skipping...")
    
    if not datasets:
        print("âŒ Error: No valid datasets found!")
        return

    # ConcatDatasetìœ¼ë¡œ ë³‘í•©
    combined_dataset = ConcatDataset(datasets)
    print(f"ğŸ”¥ Total Training Samples: {len(combined_dataset)}")
    
    dataloader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True)
    
    # ---------------------------------------------------------
    # [ëª¨ë¸ ë¡œë“œ & ì´ˆê¸°í™”]
    # ---------------------------------------------------------
    model = CollisionPredictor().cuda()
    
    # if os.path.exists(PRETRAINED_MODEL_PATH):
    #     print(f"ğŸ“¥ Loading pretrained weights from '{PRETRAINED_MODEL_PATH}'...")
    #     # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ (Key Mismatch ë°©ì§€ ë¡œì§ í¬í•¨)
    #     checkpoint = torch.load(PRETRAINED_MODEL_PATH)
        
    #     # ë§Œì•½ state_dict í‚¤ì— 'net.' ì ‘ë‘ì‚¬ê°€ ìˆë‹¤ë©´ ì œê±° (ì´ì „ ì €ì¥ ë°©ì‹ í˜¸í™˜)
    #     new_state_dict = {k.replace("net.", ""): v for k, v in checkpoint.items()}
        
    #     # ëª¨ë¸ì— ê°€ì¤‘ì¹˜ ë¡œë“œ (strict=Falseë¡œ ìœ ì—°í•˜ê²Œ ë¡œë“œ)
    #     try:
    #         model.net.load_state_dict(new_state_dict)
    #     except:
    #         # êµ¬ì¡°ê°€ ë‹¤ë¥¼ ê²½ìš° ì „ì²´ ë¡œë“œ ì‹œë„
    #         model.load_state_dict(checkpoint)
            
    #     print("âœ… Pretrained weights loaded successfully.")
    # else:
    #     print(f"âš ï¸ Warning: Pretrained model '{PRETRAINED_MODEL_PATH}' not found. Starting from scratch.")

    # ---------------------------------------------------------
    # [í•™ìŠµ ë£¨í”„]
    # ---------------------------------------------------------
    criterion = nn.BCELoss() 
    optimizer = optim.Adam(model.parameters(), lr=LR)
    
    print("ğŸš€ Transfer Learning Start...")
    model.train()
    
    best_loss = float('inf')

    for epoch in range(EPOCHS):
        total_loss = 0
        
        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f"Epoch {epoch}")
        
        for i, (features, label) in progress_bar:
            # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ (Shapeì´ ì´ìƒí•˜ë©´ ìŠ¤í‚µ)
            if features.shape[0] == 0: continue

            x = features.view(-1, 4).cuda()
            y = label.view(-1, 1).cuda()

            # Forward
            pred = model(x)
            loss = criterion(pred, y)

            # Backward
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

            avg_loss = total_loss / (i + 1)
            progress_bar.set_postfix({"avg_loss": f"{avg_loss:.4f}"})

        avg_epoch_loss = total_loss / len(dataloader)
        print(f"==== Epoch {epoch} Average Loss: {avg_epoch_loss:.6f} ====")

        # Best Model ì €ì¥
        if avg_epoch_loss < best_loss:
            best_loss = avg_epoch_loss
            torch.save(model.state_dict(), SAVE_MODEL_PATH)
            print(f"ğŸ“‰ Best adapted model updated! Saved to '{SAVE_MODEL_PATH}' (loss={best_loss:.6f})")

if __name__ == "__main__":
    transfer_train()