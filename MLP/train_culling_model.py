import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import os
import glob
from tqdm import tqdm

# 1. ë°ì´í„°ì…‹ í´ëž˜ìŠ¤ ì •ì˜ (Geometry Feature ì¶”ê°€)
class ClothCollisionDataset(Dataset):
    def __init__(self, data_dir):
        # v2 ë°ì´í„° í´ë”ë¡œ ê²½ë¡œê°€ ë§žëŠ”ì§€ ê¼­ í™•ì¸í•˜ê²Œ!
        self.file_list = sorted(glob.glob(os.path.join(data_dir, "*.npz")))
        print(f"ðŸ“‚ Found {len(self.file_list)} data files in '{data_dir}'.")
        
    def __len__(self):
        return len(self.file_list)
    
    def __getitem__(self, idx):
        # npz ë¡œë“œ
        data = np.load(self.file_list[idx])
        
        # [Input 1] ì†ë„ (N, 3)
        vel = data['vel'] 
        
        # [Input 2] ê¸°í•˜ ì •ë³´ (N, 1) - ìš°ë¦¬ê°€ ìƒˆë¡œ ì¶”ê°€í•œ í•µì‹¬ Feature!
        # ë§Œì•½ geoê°€ (N,) í˜•íƒœë¡œ ì €ìž¥ë˜ì—ˆë‹¤ë©´ reshape(-1, 1)ì´ í•„ìš”í•  ìˆ˜ ìžˆìŒ
        geo = data['geo'].reshape(-1, 1) 
        
        # [Feature Fusion] ì†ë„ì™€ ê¸°í•˜ ì •ë³´ë¥¼ í•©ì¹¨ -> (N, 4)
        # ì´ì œ ìž…ë ¥ ë²¡í„°ëŠ” [vx, vy, vz, strain] í˜•íƒœê°€ ë¨
        features = np.hstack((vel, geo))
        
        # [Label] ì¹¨íˆ¬ ê¹Šì´ (Binary Classification)
        penetration = data['label'] 
        label = (penetration > 0.001).astype(np.float32) 
        
        return torch.FloatTensor(features), torch.FloatTensor(label)

# 2. ëª¨ë¸ ì •ì˜ (ìž…ë ¥ ì°¨ì› ë³€ê²½: 3 -> 4)
class CollisionPredictor(nn.Module):
    def __init__(self):
        super(CollisionPredictor, self).__init__()
        # ìž…ë ¥: 4 (vx, vy, vz, compression_ratio)
        # ì¶œë ¥: 1 (ì¶©ëŒ í™•ë¥ )
        self.net = nn.Sequential(
            nn.Linear(4, 64),
            nn.ReLU(),
            nn.Linear(64, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.BatchNorm1d(16),
            nn.ReLU(),
            nn.Linear(16, 8),
            nn.ReLU(),
            nn.Linear(8, 1),
            nn.Sigmoid() 
        )
        
    def forward(self, x):
        return self.net(x)

def train():
    # ì„¤ì •
    DATA_DIR = "../dataset_curtain_128" 
    
    BATCH_SIZE = 1 
    LR = 0.001
    EPOCHS = 10
    
    # ë°ì´í„°ì…‹ ê²½ë¡œ ì¡´ìž¬ í™•ì¸
    if not os.path.exists(DATA_DIR):
        print(f"âŒ Error: Data directory '{DATA_DIR}' not found!")
        return

    # ë°ì´í„° ë¡œë”
    dataset = ClothCollisionDataset(DATA_DIR)
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)
    
    # ëª¨ë¸ & ìµœì í™”
    model = CollisionPredictor().cuda()
    criterion = nn.BCELoss() 
    optimizer = optim.Adam(model.parameters(), lr=LR)
    
    print("ðŸš€ Training Start with Geometry Features...")
    model.train()
    
    best_loss = float('inf')

    for epoch in range(EPOCHS):
        total_loss = 0
        
        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f"Epoch {epoch}")
        
        for i, (features, label) in progress_bar:
            # features shape: [1, N, 4] -> [N, 4]ë¡œ íŽ¼ì¹¨
            # label shape: [1, N] -> [N, 1]ë¡œ íŽ¼ì¹¨

            x = features.view(-1, 4).cuda()
            y = label.view(-1, 1).cuda()

            # Forward
            pred = model(x)
            loss = criterion(pred, y)

            # Backward
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

            avg_loss = total_loss / (i + 1)
            progress_bar.set_postfix({"avg_loss": f"{avg_loss:.4f}"})

        avg_epoch_loss = total_loss / len(dataloader)
        print(f"==== Epoch {epoch} Average Loss: {avg_epoch_loss:.6f} ====")

        # Best Model ì €ìž¥
        if avg_epoch_loss < best_loss:
            best_loss = avg_epoch_loss
            torch.save(model.state_dict(), "best_model_v2.pth") # íŒŒì¼ëª…ë„ v2ë¡œ ë°”ê¿ˆ
            print(f"ðŸ“‰ Best model updated! Saved to 'best_model_v2.pth' (loss={best_loss:.6f})")

if __name__ == "__main__":
    train()